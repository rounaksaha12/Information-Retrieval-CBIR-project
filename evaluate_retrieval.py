# -*- coding: utf-8 -*-
"""evaluate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OX_5NmCurb3VL5cy0nk2_iqqXR1-rV3l
"""

# write a function whose input is a query label,label of retrieved images and the vector of embeddings of every image in dataset
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np


def evaluate_retrieval(
    query_label, retrieved_labels, embeddings, all_images_embeddings
):
    # calculate precision at 1,5,10,20,50,100
    P_1, P_5, P_10, P_20, P_50, P_100 = 0, 0, 0, 0, 0, 0
    for i in range(100):
        if retrieved_labels[i] == query_label:
            if i == 0:
                P_1 = 1
            if i < 5:
                P_5 += 1
            if i < 10:
                P_10 += 1
            if i < 20:
                P_20 += 1
            if i < 50:
                P_50 += 1
            if i < 100:
                P_100 += 1

    P_1 = P_1 / 1
    P_5 = P_5 / 5
    P_10 = P_10 / 10
    P_20 = P_20 / 20
    P_50 = P_50 / 50
    P_100 = P_100 / 100

    # calculate recall at 1,5,10,20,50,100
    # calculate hierarchical precision at 1,5,10,20,50,100 by taking

    HP_1, HP_5, HP_10, HP_20, HP_50, HP_100 = 0, 0, 0, 0, 0, 0
    for i in range(100):
        if i == 0:
            # convert the array returned by cosine_similarity to a value

            HP_1 = cosine_similarity(
                embeddings[query_label].reshape(1, -1),
                embeddings[retrieved_labels[i]].reshape(1, -1),
            ).item()
        if i < 5:
            HP_5 += cosine_similarity(
                embeddings[query_label].reshape(1, -1),
                embeddings[retrieved_labels[i]].reshape(1, -1),
            ).item()
        if i < 10:
            HP_10 += cosine_similarity(
                embeddings[query_label].reshape(1, -1),
                embeddings[retrieved_labels[i]].reshape(1, -1),
            ).item()
        if i < 20:
            HP_20 += cosine_similarity(
                embeddings[query_label].reshape(1, -1),
                embeddings[retrieved_labels[i]].reshape(1, -1),
            ).item()
        if i < 50:
            HP_50 += cosine_similarity(
                embeddings[query_label].reshape(1, -1),
                embeddings[retrieved_labels[i]].reshape(1, -1),
            ).item()
        if i < 100:
            HP_100 += cosine_similarity(
                embeddings[query_label].reshape(1, -1),
                embeddings[retrieved_labels[i]].reshape(1, -1),
            ).item()

    # compute cosine similarity between all embedding and query label and store in a matrix
    similarity_matrix = []
    for i in range(len(all_images_embeddings)):
        similarity_matrix.append(
            cosine_similarity(
                embeddings[query_label].reshape(1, -1),
                all_images_embeddings[i].reshape(1, -1),
            ).item()
        )
    # sort the matrix in decreasing order
    similarity_matrix = np.sort(similarity_matrix)
    similarity_matrix = similarity_matrix[::-1]

    # print(similarity_matrix)

    # compute prefix sum of the sorted matrix
    prefix_sum = np.cumsum(similarity_matrix)

    #  print(prefix_sum)
    print("Current hp values: ", HP_1, HP_5, HP_10, HP_20, HP_50, HP_100)

    HP_1 /= prefix_sum[0]
    HP_5 /= prefix_sum[4]
    HP_10 /= prefix_sum[9]
    HP_20 /= prefix_sum[19]
    HP_50 /= prefix_sum[49]
    HP_100 /= prefix_sum[99]

    # print the precisions and hierarchical precisions
    print("Precision at 1,5,10,20,50,100: ", P_1, P_5, P_10, P_20, P_50, P_100)
    print(
        "Hierarchical Precision at 1,5,10,20,50,100: ",
        HP_1,
        HP_5,
        HP_10,
        HP_20,
        HP_50,
        HP_100,
    )

# test the function
embeddings = np.random.rand(100, 128)
print(embeddings)
# make a set of 200 retireved labels with each entry being a random integer between 0 and 99
retrieved_labels = np.random.randint(100, size=200)
print(retrieved_labels)
query_label = np.bincount(retrieved_labels).argmax()
print(query_label)
# make a set of 10000 embeddings with each entry being a random embedding from embeddings
all_images_embeddings = []
for i in range(5000):
    all_images_embeddings.append(embeddings[np.random.randint(100)])
# print(all_images_embeddings)
    
evaluate_retrieval(query_label, retrieved_labels, embeddings, all_images_embeddings)