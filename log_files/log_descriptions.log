Method 1:compute similarity between 100-d embeddings of all image in database and the 100-d embedding of the query image obtained through the model, retrieve top k images among them
Method 2:compute the similarity between hash embedding of all images and the hash embedding of the query image obtained through the model,take the top 2k images from based on similarity and rank top k among these based on similariy of these images with 100-d embedding of the query image and trained image embeddings


Version  			Top k value		Description
====================================================================================================================
1.0					20				all embeddings normalised
									cosine similarity between 100-d embeddings,
									cosine similarity between hash embeddings and cosine similarity between 100-d embeddings		
2.0					20				all except hash embeddings normalised
									cosine similarity between 100-d embeddings,
									dot product between hash embeddings and cosine similarity between 100-d embeddings
3.0					20				all except hash embeddings normalised
									cosine similarity between 100-d embeddings,
									hamming distance between hash embeddings and cosine similarity between 100-d embeddings [torch.cdist(trained_img_hashes, torch.unsqueeze(hash, 0), p=0)]
4.0					20				all embeddings normalised
									cosine similarity between 100-d embeddings,
									hamming distance between hash embeddings and cosine similarity between 100-d embeddings [(trained_img_hashes ^ hash).sum(dim=1)]
5.0					20				same as version 4.0, only changed the inference time to rather calculate inference 
									+ preprocess time
6.0					20				same as version 3.0, but in method 2 used only hash embeddings rather than hash
									embeddings and 100-d embeddings
7.0					20				same as version 6.0 but hierarchical precision formula error corrected
8.0					20				corrected version of 3.0 without taking 100-d embeddings in  [ error rectified in hierarchical precision ]

Method 1:compute similarity between 100-d embeddings of all image in database and the 100-d embedding of the query image obtained through the model, retrieve top k images among them
Method 2:compute the similarity between hash embedding of all images and the hash embedding of the query image obtained through the model,take the top 2k images from based on similarity and rank top k among these based on similariy of these images with 100-d embedding of the query image and trained image embeddings

The log files are zipped in log_files.zip


Version  			Top k value		Description
====================================================================================================================
1.0					20				all embeddings normalised
									cosine similarity between 100-d embeddings,
									cosine similarity between hash embeddings and cosine similarity between 100-d embeddings [error]	
2.0					20				all except hash embeddings normalised
									cosine similarity between 100-d embeddings,
									dot product between hash embeddings and cosine similarity between 100-d embeddings  [error]
3.0					20				all except hash embeddings normalised
									cosine similarity between 100-d embeddings,
									hamming distance between hash embeddings and cosine similarity between 100-d embeddings [torch.cdist(trained_img_hashes, torch.unsqueeze(hash, 0), p=0)]  [error]
4.0					20				all embeddings normalised
									cosine similarity between 100-d embeddings,
									hamming distance between hash embeddings and cosine similarity between 100-d embeddings [(trained_img_hashes ^ hash).sum(dim=1)]  [error]
5.0					20				same as version 4.0, only changed the inference time to rather calculate inference 
									+ preprocess time
6.0					20				same as version 3.0, but in method 2 used only hash embeddings rather than hash
									embeddings and 100-d embeddings


